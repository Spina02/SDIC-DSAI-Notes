\chapter{Geometric Semantic GP}\label{ch:gsgp}

Traditional Genetic Programming operators, such as subtree crossover and mutation, operate on the \textit{syntactic} structure of program trees. While effective, this approach provides little to no direct control over the \textit{behavioral} or \textit{semantic} change induced by the operators. An operator might cause a drastic change in program output or no change at all (in the case of introns), making the search process somewhat undirected.

\bfit{Geometric Semantic Genetic Programming (GSGP)} proposes a radical shift in perspective. It defines genetic operators that work directly on the semantics of the programs, treating them as points in a geometric space. By doing so, it allows for a fine-grained control over the search process, ensuring that offspring are behaviorally located "between" their parents (for crossover) or within a controlled distance of their parent (for mutation).

\section{Geometric Operators on Metric Spaces}

The foundation of GSGP lies in defining the space of solutions as a \bfit{metric space}. A metric space is a set $S$ equipped with a \bfit{distance function} (or metric) $d: S \times S \to \mathbb{R}^+$, which satisfies four key properties for any $x, y, z \in S$:
\begin{itemize}[noitemsep]
    \item \textbf{Identity:} $d(x, y) = 0 \iff x = y$ The distance is zero if and only if the points are identical.
    \item \textbf{Symmetry:} $d(x, y) = d(y, x)$ The distance from x to y is the same as from y to x.
    \item \textbf{Non-negativity:} $d(x, y) \ge 0$ Distance is always non-negative.
    \item \textbf{Triangular Inequality:} $d(x, z) \le d(x, y) + d(y, z)$ The shortest path is the direct one.
\end{itemize}

Within a metric space, we can define geometric concepts like segments and balls:
\begin{itemize}
    \item A \bfit{segment} $S(x, y)$ between two points $x$ and $y$ is the set of all points $z$ for which holds:
    $$ S(x, y) = \{z \in S \mid d(x, z) + d(z, y) = d(x, y)\} $$
    \item A \bfit{ball} $B(x, r)$ of radius $r$ centered in $x$ is the set of all points $y$ whose distance from $x$ is at most $r$:
    $$ B(x, r) = \{y \in S \mid d(x, y) \le r\} $$
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{assets/metric-space.png}
    \caption{\centering Segments and balls in different metric spaces (Euclidean, ($\mathbb{R}^2$) and Hamming, $\{0,1\}^3$)}
    \label{fig:metric_spaces}
\end{figure}

\subsection{Geometric Crossover and Mutation}
Using these definitions, we can formally characterize genetic operators:
\begin{itemize}
    \item A \bfit{geometric crossover} operator, when applied to parents $x$ and $y$, must produce an offspring $z$ that lies on the segment between them: $z \in S(x, y)$.
    \item A \bfit{geometric mutation} operator, when applied to a parent $x$, must produce an offspring $y$ that lies within a ball of a defined radius $r$ around it: $y \in B(x, r)$.
\end{itemize}

\begin{observationblock}[Exploration vs. Exploitation]
    This geometric framework provides a clear distinction between the roles of operators.
    \begin{itemize}
        \item \textbf{Crossover is for Exploitation:} A geometric crossover operator generates offspring only within the bounds defined by the parents. It cannot create anything truly new, but rather explores the space "between" existing solutions. Over generations, it is confined to the convex hull of the initial population.
        \item \textbf{Mutation is for Exploration:} A geometric mutation operator is capable of producing offspring outside the segment of the parents, effectively enlarging the search space and allowing the algorithm to escape the initial population's convex hull.
    \end{itemize}
\end{observationblock}

\subsection{Are Standard GP Operators Geometric?}
Many operators in GAs are naturally geometric. For instance, one-point crossover on binary strings with Hamming distance is a geometric crossover. However, this is \textbf{not the case for standard GP}.

The standard subtree crossover in GP is \bfit{not geometric}. A simple counterexample is crossing a tree $T$ with itself. In a metric space, the segment $S(T, T)$ contains only the point $T$ itself. Yet, applying subtree crossover to two identical copies of $T$ can produce a different tree $T'$, meaning $T' \notin S(T, T)$. This violates the definition of a geometric crossover.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{assets/gp-not-geometric.png}
    \caption{\centering An example demonstrating that standard GP subtree crossover is not geometric. Crossing a tree with itself produces a new tree, which is impossible for a geometric operator.}
    \label{fig:gp_not_geometric}
\end{figure}

\section{Geometric Semantic Operators}

Standard GP operators act on the \bfit{syntactic space} (all possible program trees), but what matters is the \bfit{semantic space} (all possible program behaviors).
A program's \bfit{semantics} are its output vector on a given set of fitness cases (inputs).

\vspace{-0.5em}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.65\textwidth]{assets/syntax-semantics.png}

    \vspace{-0.5em}

    \caption{\centering The distinction between syntax and semantics. Two different trees, $T_1$ and $T_2$ (different syntax), produce two different vectors of outputs for the same set of inputs (different semantics).}
    \label{fig:syntax_vs_semantics}
\end{figure}

\vspace{-1.5em}

The core idea of GSGP is to design operators that are geometric in the \textit{semantic space}, not the syntactic one. This requires:
\begin{enumerate}
    \item Defining a distance metric on the semantics of programs (e.g., Euclidean distance between their semantic vectors).
    \item Designing new crossover and mutation operators that construct an offspring tree whose \textit{semantics} are guaranteed to lie on the segment between the parent semantics (for crossover) or in a ball around the parent's semantics (for mutation).
\end{enumerate}

\subsection{Geometric Semantic Crossover (GSC)}
GSC generates an offspring $T_{off}$ whose semantics are a linear interpolation of the semantics of its parents, $T_1$ and $T_2$. This is achieved by constructing the offspring tree as:
$$
    T_{off} = (R \times T_1) + ((1 - R) \times T_2)
$$
Where $R$ is a randomly generated program tree whose outputs are guaranteed to be in the range $[0, 1]$. For any input, the output of $T_{off}$ will be on the segment between the outputs of $T_1$ and $T_2$.

\vspace{-0.5em}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{assets/gsc-crossover.jpg}

    \vspace{-0.5em}
    \caption{\centering The structure of Geometric Semantic Crossover.}
    \label{fig:gsc_crossover}
\end{figure}

\vspace{-1.5em}

The effect on the semantic space is that the offspring's behavior is bounded by the behavior of its parents, providing a highly controlled and exploitative search.

\subsection{Geometric Semantic Mutation (GSM)}
GSM generates a mutated offspring $T_{off}$ by adding a bounded random perturbation to the semantics of a single parent $T_1$. The construction is:
$$
    T_{off} = T_1 + (m \times R')
$$
Where $m$ is the \bfit{mutation step} (a constant that defines the mutation radius) and $R'$ is a randomly generated tree whose outputs are guaranteed to be in the range $[-1, 1]$. This ensures the offspring's semantics lie within a "ball" of a specified radius around the parent's semantics.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{assets/gsm-mutation.png}
    \caption{\centering The structure of Geometric Semantic Mutation. The offspring tree is created by adding a scaled random component (controlled by mutation step $m$) to the parent tree $T_1$.}
    \label{fig:gsm_mutation}
\end{figure}

\vspace{-1.5em}

\section{Challenges and Advancements in GSGP}
While semantically powerful, GSGP faces a significant practical challenge: the trees it produces grow exponentially with each generation. The formula for GSC, for example, combines three trees to make one, leading to rapid and unsustainable bloat.

This has led to the development of more advanced implementations like \bfit{Fast GSGP}, which use techniques such as \textbf{subtree sharing} and optimized data structures to manage this complexity, making the approach viable in practice. These methods have shown that GSGP can significantly outperform standard GP on many benchmark problems, especially in terms of generalization to unseen data.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{assets/fast-gsgp.png}
    \caption{\centering Fast GSGP illustration.}
    \label{fig:fast_gsgp}
\end{figure}