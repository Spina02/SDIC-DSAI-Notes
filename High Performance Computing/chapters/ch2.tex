\chapter{Hardware and Software}

\section{HPC Hardware}

\subsection*{Serial Computers}

A serial computer is a machine that processes one instructinon at a time and is defined by the \textbf{Von Neumann architecture} you can see in Figure \ref{fig:von_neumann}:
\begin{itemize}
    \item \textbf{Control Unit:} fetches instructions from memory, decodes them, and executes them by coordinating the activities of the other components.
    \item \textbf{Arithmetic Logic Unit (ALU):} performs arithmetic and logical operations on data.
    \item \textbf{Registers:} small, high-speed storage locations within the CPU that hold data and instructions temporarily during processing.
    \item \textbf{Memory:} stores data and instructions that the CPU needs. 
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{assets/von_neumann.png}
    \caption{Von Neumann Architecture}
    \label{fig:von_neumann}
\end{figure}

Here, the CPU fetches instructions from memory \textbf{one at a time}, decodes them, and executes them sequentially. This architecture is simple and easy to understand, but it has some limitations, such as the \textbf{Von Neumann bottleneck}, which refers to the limited bandwidth between the CPU and memory that can slow down performance.
Moreover, memory is \textbf{flat}, meaning that there is no hierarchy or differentiation between different types of memory. This can lead to inefficiencies in data access and processing, as the CPU may have to wait for data to be fetched from slower memory locations.

\subsection*{Moore Law}

Tipically, the Moore Law is stated as: "Performance doubles every 18 months". However, it is actually closer to "The number of transistors per unit cost doubles every 18 months".

The original Moore Law was formulated by Gordon Moore, co-founder of Intel, in 1965. He predicted that:

\begin{definitionblock}
    \textit{"The complexity for minimum component costs has increased at a rate of roughly a factor of two per year. [...] Over the longer term, the rate of increase is a bit more uncertain, although there is no reason to believe it will not remain nearly constant for at least 10 years." \newline
    \phantom{ } \hfill \textasciitilde Gordon Moore, 1965}
\end{definitionblock}

Dennard Scaling $\rightarrow$ from Moore's Law to performance

\begin{definitionblock}
    \textit{"Power density stays constant as transistors get smaller" \newline
    \phantom{ } \hfill \textasciitilde Robert H. Dennard, 1974}
\end{definitionblock}

The concept of Dennard scaling, named after Robert Dennard, an IBM researcher, is closely related to Moore's Law. Dennard scaling refers to the observation that as transistors shrink in size, their power density remains constant. This phenomenon allowed for the continuous increase in clock speeds and performance of microprocessors over the years. 

However, Dennard scaling began to break down around the early 2000s, as power consumption and heat dissipation became significant challenges. Consequently, the industry shifted its focus from increasing clock speeds to improving parallelism and energy efficiency.

\vspace{0.5em}

Intuitively:

\begin{itemize}
    \item Smaller transistors $\rightarrow$ shorter propagation delay $\rightarrow$ faster frequency 
    \item  Smaller transistors $\rightarrow$ smaller capacitance $\rightarrow$ lower power consumption
\end{itemize}

$$
Power \propto Capacitance \times Voltage^2 \times Frequency
$$

\subsubsection*{End of Dennard Scaling: Power wall}

The power wall is a fundamental limit on the amount of power that can be dissipated by a chip. This limit is determined by the chip's thermal design power (TDP), which is the maximum amount of heat that the cooling system can dissipate. As the number of transistors on a chip increases, the power consumed by the chip also increases, eventually reaching the TDP limit. When this limit is reached, the chip can no longer dissipate the heat generated by the transistors, leading to overheating and reduced performance.

However, the original Moore's Law is still valid, as the number of transistors per unit cost continues to double every 18 months, but no more on a single core. Instead, the industry has shifted towards multi-core processors and parallel computing to continue improving performance.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{assets/moore.jpg}
    \caption{Moore's Law}
    \label{fig:moore}
\end{figure}

This evolution marks what many computer scientists and engineers refer to as the end of the "free lunch" era, which began around 2006. Prior to this shift, software developers could rely on hardware improvements to automatically enhance their applications' performance without significant code optimization. Single-core performance scaling, which had been the primary driver of computational advances for decades, effectively plateaued as the industry encountered fundamental physical limitations.

The computing community has responded to this challenge through two complementary approaches:

\textbf{The Software Solution:} This approach emphasizes the critical importance of efficient software design and implementation. As hardware improvements no longer automatically translate to performance gains, developers must engage in deliberate "performance engineering"—applying sophisticated optimization techniques informed by deep understanding of hardware architecture. This involves careful algorithm selection, memory access pattern optimization, and exploitation of instruction-level parallelism to maximize the utilization of available hardware resources.

\textbf{The Specialized Architectural Solution:} The second approach acknowledges a fundamental shift in design constraints: while chip space has become relatively inexpensive, power consumption has emerged as the primary limiting factor. Rather than continuing to develop increasingly complex general-purpose processing cores, this approach advocates for heterogeneous computing systems. Such systems incorporate specialized accelerators (such as GPUs, TPUs, and FPGAs) that are optimized for specific computational patterns. This architectural diversification allows for significant performance improvements in targeted application domains while maintaining reasonable power consumption profiles.

These complementary strategies represent the computing industry's response to the physical limitations that have constrained traditional performance scaling. By combining software optimization with hardware specialization, the field continues to advance computational capabilities even as the straightforward scaling of single-core performance has reached its practical limits.

\section{Parallel computers}

Modern CPUs have evolved into multicore processors due to physical constraints in power consumption and heat dissipation, with manufacturers reducing clock frequencies while increasing core count to deliver greater computational throughput within manageable thermal profiles. These independent cores can execute separate instruction streams simultaneously but share critical resources including memory hierarchies, controllers, and peripheral subsystems, creating a complex environment where cores must cooperate and compete for resources. This architectural shift effectively circumvents the limitations of traditional single-core scaling but presents new challenges for software developers, who must now explicitly design for parallelism to fully leverage available computational capabilities.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{assets/hardware_accelerators.png}
    \caption{Hardware accelerators}
    \label{fig:hardware_accelerators}
\end{figure}

\begin{definitionblock}
    A \textbf{core} is the smallest unit of computing, having one or more (hardware/software) threads and is responsible for executing instructions.
\end{definitionblock}

\begin{observationblock}[Nomenclature]
    \begin{itemize}
        \item \textbf{CPU} = Central Processing Unit = Processor = Socket
        \item \textbf{Core} = execution unit within a CPU
        \item \textbf{Thread} = hardware thread = virtual core
    \end{itemize}
    Thus, a \textbf{multiprocessor} is a server with more than 1 CPU, while a \textbf{multicore} is a CPU with more than 1 core.
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.4\textwidth]{assets/multi_core_processor.png}
        \caption{Multicore processor}
        \label{fig:multi_core_processor}
    \end{figure}
\end{observationblock}

Parallel computing is a type of computation in which many calculations or processes are carried out simultaneously. Flynn Taxonomy is a classification of parallel computer architectures, proposed by Michael J. Flynn in 1966. It categorizes computer systems based on the number of instruction streams and data streams that can be processed concurrently. The four categories are shown in Table \ref{tab:hw-sw-comparison}.

\begin{table}[ht]
    \centering
    \begin{tabular}{l p{6.8cm} p{6.8cm}}
        \hline
        \textbf{} & \textbf{HW level} & \textbf{SW level} \\
        \hline
        \textbf{SISD} & 
        A Von Neumann CPU & 
        no parallelism at all \\
        \hline
        \textbf{MISD} & 
        On a superscalar CPU, different ports executing different \textit{read} on the same data & 
        ILP on same data; multiple tasks or threads operating on the same data \\
        \hline
        \textbf{SIMD} & 
        Any vector-capable hardware (vector registers on a core, a GPU, a vector processor, an FPGA, ...) & 
        data parallelism through vector instructions and operations \\
        \hline
        \textbf{MIMD} & 
        Every multi-core processor; on a superscalar CPU, different ports executing different ops on different data & 
        ILP on different data; multiple tasks or threads with different data on each core \\
        \hline
    \end{tabular}
    \caption{Comparison of SISD, MISD, SIMD, and MIMD at HW and SW levels}
    \label{tab:hw-sw-comparison}
\end{table}

While Flynn's taxonomy provided a foundational classification system in 1966, its utility for categorizing modern HPC infrastructure has diminished significantly. The dramatic evolution of CPUs and computing architectures over the past six decades has produced systems with hybrid designs that transcend these simple classifications. Nevertheless, the fundamental concepts of SIMD and MIMD remain relevant principles that continue to influence the design and implementation of contemporary HPC hardware solutions.

\subsection*{Essential Components of a HPC Cluster}

\begin{itemize}
    \item Several computers (nodes) with multiple sockets, each with multiple cores
    \item One or more networks (interconnects) to hook the nodes together
    \item One or more accelerators (GPUs, FPGAs, TPUs, ...)
    \item One or more levels of memory (cache, RAM, ...)
    \item One or more levels of storage (SSD, HDD, ...)
    \item A login/access node
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{assets/hpc_cluster.png}
    \caption{HPC Cluster Architecture}
    \label{fig:hpc_cluster}
\end{figure}

A CPU uses a \textbf{Cache hierarchy} to store data and instructions. The cache hierarchy consists of several levels of cache, each with different sizes and access times. The cache hierarchy is designed to minimize the time it takes to access data and instructions, which can significantly improve the performance of the CPU.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{assets/node_topology.png}
    \caption{Node topology}
    \label{fig:node_topology}
\end{figure}

There are different networks for different purposes:
\begin{itemize}
    \item \textbf{High-speed interconnect:} used for communication between nodes, typically using InfiniBand or high-speed Ethernet. Low latency and high bandwidth are critical for performance.
    \item \textbf{Management network:} used for administrative tasks, such as monitoring and managing the cluster. This network is typically separate from the high-speed interconnect to ensure that management tasks do not interfere with application performance.
    \item \textbf{I/O network:} used for data transfer between the compute nodes and storage systems. This network is optimized for I/O requests (NFS and/or parallel FS), latency is not as critical as bandwidth. Typical choices are Ethernet or Fibre Channel.
\end{itemize}

\subsection*{Memory}

What about memory? On a supercomputer there is a hybrid approach as for the memory placement:

\begin{itemize}
    \item \textbf{Shared memory:} the memory on a single nodes can be accessed directly by all the cores on that node, meaning that memory access is a “read/write” instructions irrespectively of what exact memory bank it refers to.
    \item \textbf{Distributed memory:} when you use many nodes at a time, a process can not directly access the memory on a different node. It need to issue a request for that, not a read/write instruction.
\end{itemize}

These are hardware concepts, i.e. they describe how the memory is physically accessible. However, they do also refer to programming paradigms, as we’ll see in a while.

\begin{minipage}{0.48\textwidth}
\textbf{Uniform memory access (UMA)}: Each processor has uniform access to memory. Also known as symmetric multiprocessing (SMP).
\end{minipage}
\begin{minipage}{0.48\textwidth}
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.8\textwidth]{assets/uma.png}
        \caption{UMA}
        \label{fig:uma}
    \end{figure}
\end{minipage}

\begin{minipage}{0.48\textwidth}
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.8\textwidth]{assets/numa.png}
        \caption{NUMA}
        \label{fig:numa}
    \end{figure}
\end{minipage}
\begin{minipage}{0.48\textwidth}
    \textbf{Non-uniform memory access (NUMA)}: Each processor has its own local memory, but can also access memory local to other processors. Accessing local memory is faster than accessing non-local memory.
\end{minipage}

\begin{warningblock}[Challenges for multicore processors]
    \begin{itemize}
        \item Need parallel algorithms to exploit multiple cores
        \item Aggravates memory wall problem (cores compete for memory bandwidth)
        \item Cache sharing and coherency issues
    \end{itemize}
\end{warningblock}

A single node can have multiple cores, each with multiple hardware threads. This introduces several levels of parallelism:

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{assets/parallelism.png}
    \caption{Levels of parallelism}
    \label{fig:parallelism}
\end{figure}

\begin{enumerate}
    \item The first level parallelism is in a single core of a CPU
    \item The second level of parallelism is between cores of a single CPU
    \item The third level of parallelism is introduced by inner cache levels
    \item The fourth level of parallelism is between CPUs of a single node.
    \item A node can also have accelerators, like GPUs or FPGAs which introduce another level of parallelism.
\end{enumerate}

\section{HPC Software}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{assets/software_stack.png}
    \caption{The Software Stack: in red the \textit{cluster middleware}} \label{fig:software_stack}
\end{figure}

\subsubsection*{The Cluster middleware}

The cluster middleware (the one in the red box in \cref{fig:software_stack}) is the software layer that sits between the hardware and the applications. 

The cluster middleware includes administration software responsible for managing user accounts and network services such as NTP and NFS, ensuring system consistency and time synchronization. Additionally, it encompasses resource management and scheduling tools (LRMS) that efficiently distribute processes, balance system load, and schedule jobs for multiple tasks, thereby optimizing overall cluster performance.

\subsubsection*{Resource Management Problem}

The Resource Management Problem in HPC environments centers around the efficient allocation of computing resources among competing users and applications. We have a pool of users and a pool of resources, but this alone is insufficient for effective operation. Three key software components bridge this gap: resource controllers that monitor and manage the available computational assets, scheduling systems that make intelligent decisions about which applications to execute based on resource availability and prioritization policies, and execution engines that handle the actual deployment and running of applications on the allocated hardware. This layered approach ensures optimal utilization of expensive HPC infrastructure while providing fair access to multiple users with diverse computational needs. The complexity of this management increases with system scale, particularly as modern supercomputers accommodate thousands of simultaneous users competing for limited computational resources.

\subsubsection*{Resources}

HPC systems manage a variety of computational resources, including CPUs, memory, storage, network bandwidth, and specialized accelerators like GPUs and FPGAs. In modern supercomputing environments, resources are often virtualized and dynamically allocated based on workload demands. This approach enables flexible resource management but introduces additional complexity in tracking, optimizing, and maintaining the system. Resource management systems must balance competing priorities such as maximizing throughput, ensuring fairness among users, accommodating urgent jobs, and maintaining energy efficiency. As illustrated in Figure \ref{fig:resources}, these resources form an interconnected ecosystem where efficient allocation directly impacts overall system performance and user satisfaction.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{assets/resources.png}
    \caption{Resources in a HPC cluster}
    \label{fig:resources}
\end{figure}

\begin{definitionblock}[Scheduling]
    Scheduling is the method by which work specified by some means is assigned to resources that complete the work
\end{definitionblock}

Some definitions of scheduling:

\begin{itemize}
    \item \textbf{Batch Scheduler}: software responsible for scheduling the users' jobs on the cluster.
    \item \textbf{Resource Manager}: software that enable the jobs to connect the nodes and run
    \item \textbf{Node}: computer used for its computational power
    \item \textbf{Login/Master node}: it's through this node that the users will submit/launch/manage jobs
\end{itemize}

\subsubsection*{Batch Scheduler}

The \textbf{batch scheduler} is a critical component of the HPC software stack, responsible for managing the allocation of computational resources to user applications. It serves as the primary interface between users and the underlying hardware, ensuring that jobs are executed efficiently and fairly. The batch scheduler receives job submissions from users, evaluates resource availability, and makes intelligent decisions about job placement and execution. By optimizing resource utilization and minimizing job wait times, the batch scheduler plays a central role in maximizing the overall performance of the HPC system.

\vspace{0.5em}

The batch scheduler faces the challenging task of balancing multiple competing objectives:

\begin{itemize}
    \item \textbf{User Satisfaction:} Allocating resources for applications according to their specific requirements and users' rights, while ensuring minimal response time and high reliability.
    
    \item \textbf{Administrative Efficiency:} Meeting administrative goals by maintaining high resource utilization, operational efficiency, and effective energy management.
\end{itemize}

This balancing act requires sophisticated algorithms and policies that can adapt to changing workloads and priorities within the HPC environment.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{assets/batch_scheduler.png}
    \caption{Batch Scheduler Architecture}
    \label{fig:batch_scheduler}
\end{figure}

Modern HPC schedulers typically implement a layered architecture:

\begin{itemize}
    \item \textbf{Resource Management Layer:} Handles the low-level aspects of job execution, including launching processes, cleaning up after completion, and continuous monitoring of resource usage.
    
    \item \textbf{Job Management Layer:} Manages both batch and interactive jobs with features such as:
    \begin{itemize}
        \item \textit{Backfilling:} Filling idle resources with smaller jobs that won't delay scheduled larger jobs
        \item \textit{Advanced scheduling:} Optimizing job placement based on multiple constraints
        \item \textit{Job control:} Supporting suspend/resume operations and preemption when needed
        \item \textit{Workflow management:} Handling job dependencies and automatic resubmission
        \item \textit{Resource reservation:} Enabling advance booking of computational resources
    \end{itemize}
    
    \item \textbf{Workload Management Layer:} Implements comprehensive scheduling policies including:
    \begin{itemize}
        \item Fair-sharing mechanisms to allocate resources equitably among users and groups
        \item Quality of Service (QoS) provisions for prioritizing critical applications
        \item Service Level Agreement (SLA) enforcement to meet contracted performance metrics
        \item Energy-saving strategies to optimize power consumption
    \end{itemize}
\end{itemize}

In many large-scale HPC environments, this workload management functionality may be provided by dedicated software that interfaces with the underlying resource manager, creating a flexible and powerful scheduling ecosystem that can adapt to the specific needs of the organization.

\subsection*{Local Resource Manager}

A Local Resource Manager System (LRMS) provides the critical interface between the computing resources and the users' workloads. These systems are responsible for allocating resources, launching jobs, tracking their execution, and managing the overall utilization of the HPC cluster.

\subsubsection*{Main LRMS packages}

Several LRMS solutions have emerged to address the complex scheduling and resource management needs of HPC environments. Each offers different features, advantages, and licensing models:

\begin{itemize}
    \item \textbf{IBM Platform LSF (Load Sharing Facility)}
    \begin{itemize}
        \item Commercial solution with enterprise-level support
        \item Offers advanced workload management capabilities for heterogeneous environments
        \item Provides comprehensive policy management, reporting, and analytics
        \item Notable for its fault tolerance and high availability features
    \end{itemize}
    
    \item \textbf{Univa Grid Engine (UGE)}
    \begin{itemize}
        \item Commercial solution that evolved from Sun Grid Engine (SGE)
        \item Specializes in managing complex workloads across distributed computing resources
        \item Features advanced job scheduling algorithms and resource allocation policies
        \item Supports containerization and cloud integration
    \end{itemize}
    
    \item \textbf{PBS Professional (PBSPRO)}
    \begin{itemize}
        \item Originally commercial, now available in both open-source and commercial versions
        \item Commercial support provided through Altair Engineering
        \item Offers sophisticated scheduling capabilities for heterogeneous computing resources
        \item Previously available on ORFEO but has been replaced
    \end{itemize}
    
    \item \textbf{SLURM (Simple Linux Utility for Resource Management)}
    \begin{itemize}
        \item Open-source solution with commercial support options
        \item Currently deployed on ORFEO for student access
        \item Highly scalable and fault-tolerant architecture
        \item Used by many of the world's top supercomputers
    \end{itemize}
\end{itemize}

\subsubsection*{SLURM in Depth}

SLURM's development began in 2002 at Lawrence Livermore National Laboratory, where it was originally designed as a resource manager for Linux clusters. The name initially stood for \textit{Simple Linux Utility for Resource Management}. The system evolved significantly over time, with advanced scheduling plugins being added in 2008 to enhance its capabilities. Today, SLURM consists of approximately 550,000 lines of C code and maintains an active global user community and development ecosystem that continues to improve and extend its functionality.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{assets/slurm_architecture.png}
    \caption{Simplified SLURM Architecture}
    \label{fig:slurm_architecture}
\end{figure}

\textbf{Key Entities in SLURM:}
\begin{itemize}
    \item \textbf{Jobs:} Resource allocation requests that define the computational resources required
    \begin{itemize}
        \item Specified through command-line tools or script directives
        \item Include parameters such as required nodes, cores, memory, and time limits
    \end{itemize}
    
    \item \textbf{Job Steps:} Sets of (typically parallel) tasks within a job allocation
    \begin{itemize}
        \item Usually correspond to MPI applications or multi-threaded programs
        \item Utilize resources from the parent job's allocation
        \item Multiple steps can execute sequentially or concurrently within a job
        \item Offer lower overhead than full job submissions
    \end{itemize}
    
    \item \textbf{Partitions:} Job queues with specific limits and access controls
    \begin{itemize}
        \item Configure access policies and resource limits for different user groups
        \item Enable prioritization of workloads based on organizational needs
        \item Allow for specialized hardware to be allocated to appropriate jobs
    \end{itemize}
    
    \item \textbf{QoS (Quality of Service):} Defines limits, policies, and priorities
    \begin{itemize}
        \item Controls maximum resource allocation per user or group
        \item Enforces priorities between competing workloads
        \item Implements site-specific policies for resource allocation
        \item Provides mechanisms for preemption and resource guarantees
    \end{itemize}
\end{itemize}

\textbf{Architecture Components:}
\begin{itemize}
    \item \textbf{slurmctld} - Central controller daemon managing the overall state of the cluster
    \item \textbf{slurmd} - Node-level daemon running on each compute node
    \item \textbf{slurmdbd} - Optional database daemon for accounting records
    \item \textbf{User commands} - Tools like \texttt{sbatch}, \texttt{srun}, \texttt{squeue}, and \texttt{scancel} for job submission and management
\end{itemize}

SLURM's modular design allows for customization through plugins, making it adaptable to various hardware configurations and scheduling policies. Its scalability has been demonstrated on systems with over 100,000 compute nodes, making it suitable for the largest supercomputing installations in the world.

\subsection*{Scientific Software}

Scientific software encompasses a wide range of applications and libraries designed to facilitate complex computations, simulations, and data analysis in various scientific domains. 
It is composed by different layers:
\begin{itemize}
    \item \textbf{User's applicaations (both parallel and serial):} these are the applications that the users run on the cluster. They can be either commercial or open-source.
    \item \textbf{Parallel libraries:} these are libraries that provide parallel functionality to the user's applications. They can be either commercial or open-source.
    \item \textbf{Mathematical/Scientific libraries:} these are libraries that provide mathematical and scientific functionality to the user's applications. They can be either commercial or open-source.
    \item \textbf{I/O libraries:} these are libraries that provide I/O functionality to the user's applications. They can be either commercial or open-source.
    \item \textbf{Compilers:} these are the compilers that the users use to compile their applications. They can be either commercial or open-source.
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{assets/scientific_software.png}
    \caption{Scientific Software Stack}
    \label{fig:scientific_software}
\end{figure}

There is not much \textbf{standardization} for scientific software in HPC, as every app has a different software stack. This is done to get the best possible performance for the specific application. Usually usability and reuse are traded off for performance. 
This creates a lot of problems for the users, as they have to learn how to use different software stacks for different applications. Moreover, the software stack is usually not portable, as it is optimized for a specific architecture. Here rises the \textbf{Dependency Nightmare}, where different applications require different versions of the same library, which can lead to conflicts and incompatibilities.

Usually the scientific software is installed in \texttt{/opt/cluster/software} (or similar) and mounted read-only on the nodes using NFS. It is generally managed using environment modules, which allow users to load and unload different software stacks as needed.
Modules allow to dynamically modify the user's environment (\texttt{PATH}, \texttt{LD\_LIBRARY\_PATH}, etc.) to use different versions of the same software. Some commands are:
\begin{itemize}
    \item \texttt{module avail}: list all available modules
    \item \texttt{module load <module>}: load a module
    \item \texttt{module unload <module>}: unload a module
    \item \texttt{module list}: list all loaded modules
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{assets/orfeo_modules.png}
    \caption{Orfeo Environment Modules}
    \label{fig:orfeo_modules}
\end{figure}

\newpage
\subsection*{Complilers}

High level languages need to be compiled to a stream of machine instructions that can be executed by the CPU. The \textbf{compiler} is the software that does this job. 

In HPC environments, the choice of compiler can significantly impact application performance. Several options are available:

\textbf{Free Compilers: GNU Suite}
\begin{itemize}
    \item Always available on virtually all Linux/Unix platforms
    \item Includes GCC (C/C++) and GFortran (Fortran) compilers
    \item Multiple versions with varying feature support
    \item Fundamental and reliable, but may lack performance optimizations for specific architectures
    \item Open source with strong community support
\end{itemize}

\textbf{Commercial Compilers: Intel Suite}
\begin{itemize}
    \item Provides a comprehensive software stack including:
    \begin{itemize}
        \item Highly optimized C, C++, and Fortran compilers
        \item Performance libraries (MKL, IPP, TBB)
        \item Profiling and benchmarking tools
        \item MPI implementations
    \end{itemize}
    \item Specifically optimized for Intel architectures
    \item Often delivers superior performance for floating-point computations
    \item Excellent vectorization capabilities
\end{itemize}

\textbf{NVIDIA HPC SDK (formerly PGI)}
\begin{itemize}
    \item Strong compiler suite with good performance characteristics
    \item Features valuable HPC extensions:
    \begin{itemize}
        \item OpenACC directives for GPU programming
        \item CUDA Fortran for direct GPU programming from Fortran
        \item Advanced optimization capabilities
    \end{itemize}
    \item Community edition available for free
    \item Particularly well-suited for heterogeneous CPU/GPU computing
\end{itemize}

The choice of compiler depends on various factors including the target architecture, specific performance requirements, and available budget. Many HPC centers provide multiple compiler options, allowing users to select the most appropriate tool for their particular application requirements.

\begin{observationblock}[ORFEO Compiler]
    On ORFEO there is an openMPI installation, which includes the GNU compilers.
\end{observationblock}