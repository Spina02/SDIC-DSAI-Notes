\chapter*{Abstract}

As a student of Scientific and Data Intensive Computing, I've created these notes while attending the \textbf{Probabilistic Machine Learning} course.

\vspace{1em}

This collection introduces ideas and instruments of machine learning from a probabilistic perspectiveâ€”an approach that continues to grow in importance and serves as the foundation for many recent successes in generative Artificial Intelligence. The notes begin with a discussion on the fundamental role of probability and mathematics in machine learning, providing a framework for understanding ML concepts through this powerful lens.

\vspace{1em}

Throughout the course, we will focus on the following topics:

\begin{itemize}
    \item Basics of probability and probabilistic inference
    \item Probabilistic formulation of learning (Empirical Risk Minimization and PAC Learning)
    \item Graphical Models
    \item Inference with graphical models: belief propagation
    \item Hidden Markov Models for sequential data
    \item Bayesian Linear Regression and Classification, Laplace approximation, Model Selection
    \item Kernel Regression and Kernel functions, Gaussian Processes for regression (hints)
    \item Monte Carlo sampling
    \item Expectation Maximization and Variational Inference
    \item Bayesian Neural Networks
    \item Generative Modelling: Variational Autoencoders and Diffusion Processes
\end{itemize}

\vspace{1em}

The structure of these notes follows the natural progression from fundamental probabilistic concepts to advanced generative models, emphasizing both theoretical foundations and practical applications. While these notes were primarily created for my personal study, they may serve as a valuable resource for fellow students and professionals interested in probabilistic machine learning.