\chapter{Introduction to Markov Chains}

\section{From Discrete Jumps to Continuous Diffusion}

In the previous sections, we modeled stochastic systems using Stochastic Differential Equations (SDEs), which describe the infinitesimal evolution of processes with continuous paths, like the Ornstein-Uhlenbeck process. However, many systems in physics, chemistry, and biology are more naturally described by discrete "jumps" between states. Examples include a molecule switching between chemical species, an ion channel opening or closing, or a population changing by single-birth or death events.

These phenomena are governed by \textbf{jump processes}, where the system remains in a given state for a random period before instantaneously jumping to a new state. The evolution of the probability distribution for such a process is not described by a Fokker-Planck equation but by a more general framework: the \textbf{Master Equation}.

\subsubsection{The Master Equation}
Let's consider a process where the state variable $x$ can take any value in a continuous state space. The core of a jump process is the \textbf{transition rate} (or jump kernel) $\Omega(y,x)$, which defines the probability per unit time of a jump occurring \textit{from} state $y$ \textit{to} state $x$.

The probability of a system in state $y$ jumping to any state within a small region around $x$ in an infinitesimal time interval $dt$ is given by:
$$
\text{Prob}(\text{jump } y \to x \text{ in } dt) = \Omega(y,x)dt
$$
Conversely, the probability that the system, currently in state $x$, does \bfit{not} jump to any other state during $dt$ is one minus the total probability of jumping \textit{out} of $x$:
$$
\text{Prob}(\text{no jump from } x \text{ in } dt) = 1 - \left( \int \Omega(x,s)ds \right)dt
$$
The Master Equation describes the time evolution of the probability density $P(x,t)$ by balancing the probability flows into and out of state $x$. The rate of change of $P(x,t)$ is the sum of all probability flowing \textit{in} from other states $s$ (the gain term) minus the total probability flowing \textit{out} to all other states $s$ (the loss term). 

This balance gives the integro-differential Master Equation:
$$
\boxed{
\frac{\partial P(x,t)}{\partial t} = \underbrace{\int P(s,t)\Omega(s,x)ds}_{\text{Gain: Jumps from } s \text{ to } x} - \underbrace{P(x,t) \int \Omega(x,s)ds}_{\text{Loss: Jumps from } x \text{ to } s}
}
$$

\subsubsection{Deriving the Diffusion Equation}
A profound connection exists between discrete jump processes and continuous diffusion processes. Under the right conditions, a process consisting of many small, frequent jumps becomes indistinguishable from a continuous process described by a Fokker-Planck equation. We can demonstrate this by considering two simple jump models.

\begin{exampleblock}[The Uniform Jump Process]
Consider a particle that performs random jumps where the jump destination is uniformly distributed within a small interval of length $2\epsilon$ around its current position. If the particle is at $s$, it can jump to any $x \in [s-\epsilon, s+\epsilon]$. The jump kernel can be written as:
$$
\Omega(s,x) = C \cdot \mathbb{I}_{[s-\epsilon, s+\epsilon]}(x)
$$
where $C$ is a constant representing the overall jump frequency and $\mathbb{I}$ is the indicator function, therefore $\mathbb{I}$ will be $1$ in the set and $0$ outside. Thus I have the Master Equation:
$$
\partial_t P = -2\epsilon C P(x, y) + C \int_{x-\epsilon}^{x+\epsilon} P(y, t) dy
$$
Now define $y = z + x$, then
$$
\int_{x-\epsilon}^{x+\epsilon} P(y, t) dy = \int_{-\epsilon}^{\epsilon} P(x + z, t) dz
$$
Since $\epsilon$ is small, I can Taylor expand $P(x + z, t)$ around $x$:
$$
P(x + z, t) = P(x, t) + z \partial_x P(x, t) + \frac{z^2}{2} \partial_x^2 P(x, t) + \ldots
$$
Therefore
$$
\begin{array}{rl}
    \displaystyle C \int_{-\epsilon}^{\epsilon} P(x + z, t) dz & \displaystyle= C \left[ 2\epsilon + 0 \cdot \partial_x  + \frac{1}{2}\frac{1}{3} 2\epsilon^3 \partial_x^2  \right]P(x, t)\\[0.8em]
    &\displaystyle= C \left[ 2\epsilon + \frac{1}{3} \epsilon^3 \partial_x^2 \right]P(x, t)
\end{array}
$$
Putting everything together, we obtain
$$
\partial_t P(x, t) = \frac{C \epsilon^3}{3} \partial_x^2 P(x, t)
$$
To have $\frac{C \epsilon^3}{3} = O(1)$, we need $C \propto 1/\epsilon^3$, which is actially a huge jump rate.

\vspace{0.5em}

Note that this is the formula for the PDF associated with a Wiener process, so a random walk process as described is described by a Wiener process.
\end{exampleblock}

\newpage

\begin{exampleblock}[The Fixed-Step Random Walk]
Now consider a different model where jumps are of a fixed size $\pm\epsilon$. The transition rate is described by Dirac delta functions:
$$
\Omega(y,x) = C \cdot \delta(|x-y| - \epsilon)
$$
Therefore,
$$
\partial_t P = \int \left( P(y, t) \Omega(y, x) - P(x, t) \Omega(x, y) \right) dy
$$
As before,
$$
\partial_t P = C \left[ P(x - \epsilon, t) + P(x + \epsilon, t) - 2P(x, t) \right]
$$
and thus
$$
\partial_t P = C \left( P(x + \epsilon, t) - P(x, t) + P(x - \epsilon, t) - P(x, t) \right)
$$

We can now divide above and below by $\epsilon^2$ and take the incremental ratio as $\epsilon \to 0$, obtaining
$$
\partial_t P = \epsilon^2C \frac{P(x + \epsilon, t) - 2P(x, t) + P(x - \epsilon, t)}{\epsilon^2} = C \epsilon^2 \partial_x^2 P(x, t)
$$
Even for this discrete case, we obtain again the equation for the PDF of a Wiener process. However, there is something subtle: if $C$ is finite, the process does not diffuse in the limit $\epsilon \to 0$. To have a finite rate of change of probability, the diffusion coefficient must be defined as
$$
\lim_{\epsilon \to 0} C \epsilon^2 = O(1)
$$
So we must have $C \propto 1/\epsilon^2$.

\end{exampleblock}

\subsection{The Diffusion Limit and the Wiener Process}
In both examples, we found that a process of discrete jumps can be described by a diffusion equation in the limit of small jump sizes ($\epsilon \to 0$). However, for the diffusion coefficient $D$ to remain finite and non-zero in this limit, the jump rate $C$ must scale appropriately:

\vspace{0.5em}

\begin{itemize}
    \item For uniform jumps: $D = C\epsilon^3/3 \implies C \propto 1/\epsilon^3$.
    \item For fixed-step jumps: $D = C\epsilon^2 \implies C \propto 1/\epsilon^2$.
\end{itemize}

\vspace{0.5em}

In both cases, the jump rate must diverge as the jump size shrinks. This is the \textbf{diffusion limit}: a macroscopic diffusion process emerges from an infinite number of infinitesimally small, infinitely frequent jumps.

The resulting equation,
$$
\frac{\partial P}{\partial t} = D \frac{\partial^2 P}{\partial x^2}
$$
is precisely the Fokker-Planck equation for a scaled \textbf{Wiener process} described by the SDE $dx = \sqrt{2D}dW_t$. This provides a powerful microscopic justification for the SDE framework: continuous diffusion models can be viewed as the large-scale limit of underlying discrete jump phenomena.

\newpage
\subsection{The Discrete-Space Limit: The CTMC}

Let us now consider the case where the state space remains discrete. Specifically, take a random walk on the integers, $x(t) \in \mathbb{Z}$, where transitions (jumps) can only occur to neighboring sites, i.e., from $n$ to $n+1$ or $n-1$. Each jump occurs with rate $r$.

Let us specify the \bfit{jumping rates} for this process:
$$
\Omega(s,x) = r \delta(|x-s|-1) = r \delta(x-(s+1)) + r \delta(x-(s-1))
$$
This expression indicates that transitions are only allowed between neighboring sites, with each jump occurring at rate $r$.

Next, we can write down the corresponding \bfit{Master equation}. Here, time is continuous ($t \in \mathbb{R}$), and the state variable $x$ takes integer values ($x \in \mathbb{Z} \subset \mathbb{R}$):
\begin{align*}
\frac{\partial P(x,t)}{\partial t} &= \int P(s,t) \Omega(s,x) ds - P(x,t) \int \Omega(x,s) ds \\
&= \int P(s,t) r \delta(|x-s|-1) ds - 2r P(x,t)
\end{align*}
In this setup, the probability $P(s,t)$ contributes only for the two possible jumps to $x$ from its immediate neighbors, $x+1$ and $x-1$.
\begin{align*}
&= \ \ r \underbrace{P(x+1,t)}_{backward} \ \ + \ \ r \underbrace{P(x-1,t)}_{forward} \ \ - \underbrace{2r P(x,t)}_{from\ x\ to\ others}
\end{align*}

This is the master equation for a \textbf{Continuous-Time Markov Chain (CTMC)} on the integers:
$$
\frac{dP_n(t)}{dt} = r \left[ P_{n-1}(t) + P_{n+1}(t) - 2P_n(t) \right]
$$

This equation describes a process that evolves in continuous time but jumps between discrete states.

\subsubsection{General Case: Multiple Jump Sizes}

The nearest-neighbor random walk can be generalized to allow jumps of arbitrary length. Consider a process where time remains continuous but the state space is discrete, $x \in \mathbb{Z}$. We allow transitions between any two states $a$ and $s$, where the jump size is $j = s - a$. The transition rate can be written as:
$$
\Omega(a,s) = \sum_{j \in \mathbb{Z}} K_j \delta(s-a-j)
$$
where $K_j$ represents the rate of jumps of size $j$. This formulation encompasses a wide range of jump processes: choosing $K_1 = K_{-1} = r$ and $K_j = 0$ for $|j| \neq 1$ recovers the nearest-neighbor case.

Substituting this general form into the Master equation yields:

$$
\begin{array}{rl}
\displaystyle\frac{\partial P(x,t)}{\partial t} & \displaystyle= \sum_{j \in \mathbb{Z}} \int P(s,t) K_s \delta(s-x-j) ds - P(x,t) \sum_{j \in \mathbb{Z}} \int K_{x-a} \delta(x-a-j) da\\[1.5em]
& \displaystyle= \sum_{j \in \mathbb{Z}} K_j P(x-j,t) - P(x,t) \sum_{j \in \mathbb{Z}} K_j
\end{array}
$$

This equation describes the evolution of the probability distribution when the system can make jumps of various sizes, each occurring at its characteristic rate $K_j$.

\subsection{Application: The Stochastic SIR Epidemic Model}

The deterministic SIR (Susceptible-Infected-Recovered) model describes the dynamics of an epidemic through the coupled differential equations:
$$
\begin{cases}
    S' = -\beta \frac{I}{N} S \\
    I' = \beta \frac{I}{N} S - \gamma I
\end{cases}
$$
where $S(t)$ is the number of susceptibles, $I(t)$ is the number of infected, $\beta$ is the transmission rate, $\gamma$ is the recovery rate, and $N$ is the total population size. The number of recovered individuals is $R(t) = N - S(t) - I(t)$.

While this deterministic model provides valuable insights for large populations, it fails to capture the inherent randomness of infection and recovery events. For finite populations, especially smaller communities, stochastic effects can be significant and may lead to qualitatively different behavior, such as stochastic extinction of the epidemic.

\subsubsection{Stochastic Formulation}

A more appropriate model is to represent the epidemic as a continuous-time Markov chain, with the state space defined as:
$$
x(t) = (S(t), I(t)) \in C \subseteq \mathbb{N}^2
$$
where $C = \{(S,I) \in \mathbb{N}^2 \mid S + I \leq N\}$ represents the constraint that the total number of susceptible and infected individuals cannot exceed the population size.

In any infinitesimal time interval $(t, t+dt)$, only two types of events can occur:

\begin{enumerate}
    \item \textbf{Recovery Event}: The transition is $(S,I) \to (S,I-1)$, with probability:
    $$\text{Prob}[x(t+dt) = (S, I-1) \mid x(t) = (S,I)] = \gamma I \, dt$$
    
    \item \textbf{Infection Event}: The transition is $(S,I) \to (S-1,I+1)$, with probability:
    $$\text{Prob}[x(t+dt) = (S-1, I+1) \mid x(t) = (S,I)] = \beta \frac{I}{N} S \, dt$$
\end{enumerate}

\subsubsection{Transition Rates and Master Equation}

The transition rate function $\Omega(y,x)$ describes the rate of jumping from state $y$ to state $x$. For the SIR model, this takes the form:
\begin{align*}
\Omega(y,x) &= \gamma I_y \delta\left(y - x - \begin{pmatrix} 0 \\ 1 \end{pmatrix}\right) + \beta \frac{I_y}{N} S_y \delta\left(y - x - \begin{pmatrix} 1 \\ -1 \end{pmatrix}\right)
\end{align*}
where $y = (S_y, I_y)$ and $x = (S_x, I_x)$. The first term represents recovery events (decreasing $I$ by 1), while the second term represents infection events (decreasing $S$ by 1 and increasing $I$ by 1).

To derive the Master equation for state $(S,I)$, we must consider all possible transitions \textit{into} it:
\begin{itemize}
    \item From $(S+1, I-1)$ via an infection event, occurring at rate $\beta \frac{(I-1)}{N}(S+1)$
    \item From $(S, I+1)$ via a recovery event, occurring at rate $\gamma(I+1)$
\end{itemize}

The outflow from state $(S,I)$ occurs at total rate $\gamma I + \beta \frac{IS}{N}$.

The resulting Master equation is:
$$
\frac{\partial P(S,I,t)}{\partial t} = \underbrace{\beta \frac{(I-1)}{N}(S+1)P(S+1, I-1,t)}_{\text{infection}} + \underbrace{\gamma(I+1)P(S, I+1,t)}_{\text{recovery}} - \underbrace{\left(\gamma I + \beta \frac{I S}{N}\right)P(S,I,t)}_{\text{outflow}}
$$

This equation governs the time evolution of the probability distribution over all possible epidemic states and captures the stochastic nature of individual infection and recovery events.

\section{From Continuous to Discrete Time: Intro to DTMCs}

In a discrete-time Markov chain (DTMC), both \bfit{time and state space are discrete}: time steps $t$ are non-negative integers ($t \in \mathbb{N} \cup \{0\}$), and states $x(t)$ take values in a discrete set ($x(t) \in \mathbb{N} \subset \mathbb{Z}^n$).

\vspace{0.5em}

The \textbf{Transition probability} is the probability of jumping from a source state $\sigma$ at time $t$ to a target state $\alpha$ at time $t+1$ is defined as:
$$
P\{x(t+1) = \alpha \mid x(t) = \sigma\} = \theta_{\sigma\alpha} \in [0,1]
$$

The evolution of the probability of being in state $\alpha$ at time $t+1$ is given by:
$$
P_\alpha(t+1) = \sum_{\sigma} P_\sigma(t) \theta_{\sigma\alpha}
$$
where $P_\sigma(t)$ is the probability of being in state $\sigma$ at time $t$. This can be rewritten by separating the contribution from staying in the same state ($\sigma = \alpha$) and from transitions from other states ($\sigma \neq \alpha$):
$$
P_\alpha(t+1) = P_\alpha(t) \theta_{\alpha\alpha} + \sum_{\sigma \neq \alpha} P_\sigma(t) \theta_{\sigma\alpha}
$$

Recall that the probability of remaining in state $\alpha$ is:
$$
\theta_{\alpha\alpha} = 1 - \sum_{\beta \neq \alpha} \theta_{\alpha\beta}
$$
since the total probability of leaving state $\alpha$ to any other state $\beta \neq \alpha$ is $\sum_{\beta \neq \alpha} \theta_{\alpha\beta}$.

Substituting this into the previous equation, we obtain the \textbf{Master equation} for a DTMC:
$$
P_\alpha(t+1) - P_\alpha(t) = \sum_{\sigma \neq \alpha} P_\sigma(t) \theta_{\sigma\alpha} - \sum_{\beta \neq \alpha} P_\alpha(t) \theta_{\alpha\beta}
$$
This equation describes the net change in probability for state $\alpha$: the inflow from all other states minus the outflow from $\alpha$ to all other states.

\subsection{Links between DTMCs and CTMCs}

The Master equation for a DTMC provides insight into the relationship with continuous-time Markov chains (CTMCs). To see this, consider rescaling time by a small interval $u$:
$$
\frac{P_\alpha(t+u) - P_\alpha(t)}{u} = \frac{1}{u} \sum_{\sigma \neq \alpha} P_\sigma(t) \theta_{\sigma\alpha} - \frac{1}{u} \sum_{\beta \neq \alpha} P_\alpha(t) \theta_{\alpha\beta}
$$

In the limit as $u \to 0^+$, the left-hand side approaches the time derivative:
$$
\frac{d}{dt} P_\alpha(t) = \lim_{u \to 0^+} \frac{P_\alpha(t+u) - P_\alpha(t)}{u}
$$

For this limit to make sense, the transition probabilities must scale linearly with $u$:
$$
\theta_{\sigma\alpha} = \Omega(\sigma, \alpha) u + O(u^2)
$$
where $\Omega(\sigma, \alpha)$ is the transition rate from $\sigma$ to $\alpha$ in the CTMC, and $u = dt$.

Thus, in the infinitesimal limit,
$$
\theta_{\sigma\alpha} \approx \Omega(\sigma, \alpha) dt
$$

This demonstrates two key points:
\begin{enumerate}
    \item The probability of a transition in an infinitesimal interval $(t, t+dt)$ is proportional to $dt$, consistent with the definition of transition rates in CTMCs.
    \item There is a direct and rigorous connection between the discrete-time and continuous-time Markov chain formulations.
\end{enumerate}

\subsection{Example: SIR Model with Vital Dynamics}

Consider the SIR model with vital dynamics (birth \& death), described by the system:
$$
\begin{cases}
S' = \mu(1 - S) - \beta \frac{I}{N} S \\
I' = \beta \frac{I}{N} S - (\gamma + \mu) I \\
\end{cases}
$$
where $R(t) = N - S(t) - I(t)$. Here, we assume $S$ and $I$ are large enough to approximate the underlying CTMC by this deterministic system.

To incorporate stochasticity in the birth/death and contact rates, we let these parameters fluctuate:
$$
\begin{cases}
    \mu \rightarrow \mu + \omega_\mu \xi_\mu(t) \\
    \beta \rightarrow \beta + \omega_\beta \xi_\beta(t) \\
\end{cases}
$$
where $\xi_\mu(t)$ and $\xi_\beta(t)$ are white noise processes. Substituting these into the original system yields:
$$
\begin{cases}
\displaystyle \dot S = \mu (1-S) - \beta \frac{I}{N} S + (1-S)\omega_\mu \xi_\mu(t) - \beta \frac{I}{N} S \omega_\beta \xi_\beta(t) \\[0.6em]
\displaystyle \dot I = \beta \frac{I}{N} S - (\gamma + \mu) I + \beta \frac{I}{N} S \omega_\beta \xi_\beta(t) - \mu I \omega_\mu \xi_\mu(t)
\end{cases}
$$

To clarify the structure, define the state vector $x = \begin{pmatrix} S \\ I \end{pmatrix}$, the deterministic drift
$$
f(x) = \begin{pmatrix} \mu (1-S) - \beta \frac{I}{N} S \\[0.6em] \beta \frac{I}{N} S - (\gamma + \mu) I \end{pmatrix}
$$
and the noise coefficient matrix
$$
B(x) = 
\begin{pmatrix}
(1-S)\omega_\mu & -\frac{\beta I}{N} S \omega_\beta \\[0.6em]
-I\omega_\mu & \frac{\beta I}{N} S \omega_\beta
\end{pmatrix}
$$
With these, the system can be compactly written as the 2D Itô SDE:
$$
dx = f(x)dt + B(x)dW, \qquad \text{where } dW = \begin{pmatrix} dW_\mu \\ dW_\beta \end{pmatrix}
$$

For simulation, discretize the time interval $[0, T]$ into $N$ sub-intervals of length $h = T/N$, and denote $x_j = x(jh)$. The Euler-Maruyama scheme gives:
$$
x_{j+1} = x_j + h f(x_j) + \sqrt{h} B(x_j) \begin{pmatrix} C_j \omega_\beta \\ G_j \omega_\mu \end{pmatrix}
$$
where $C_j, G_j \sim \mathcal{N}(0,1)$ are independent standard normal random variables.

More generally, for $x \in \Omega \subset \mathbb{R}^n$, the Fokker-Planck equation associated to the Itô SDE
$$
dx = a(x)dt + B(x)dW, \qquad \text{where } W \in \mathbb{R}^{n_W},\ B \in \mathbb{R}^{n \times n_W}
$$
is
$$
\begin{cases}
\partial_t P(x,t) = -\text{div}(a(x)P(x,t)) + \frac 12 \sum_{i,j} \partial^2_{x_i x_j} (C_{x_i x_j} P(x,t))\\
\int_\Omega P(x,t) dx = 1
\end{cases}
$$
where $C(x) = B(x)B(x)^T$ is the diffusion matrix. However, this equation is generally too complex to solve analytically.





