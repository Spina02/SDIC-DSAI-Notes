\chapter{Stochastic Numerical Methods}

The non-differentiability of the Wiener process path fundamentally breaks the foundation of classical calculus, rendering traditional analytical techniques inadequate for stochastic differential equations. This mathematical obstacle necessitates the development of an entirely new framework—stochastic calculus, with its own integration theory and differentiation rules.

\vspace{-0.7em}

\section{The Differential Form of SDEs: Itô Equation}

Let's reconsider Newton's second law. In its most common form, it is written as $F=ma$. However, its more fundamental statement relates force to the change in momentum $p=mv$, expressed in differential form as:
$$
dp = F dt
$$
This form is more general. For instance, consider the motion of a rocket, whose mass $m(t)$ changes as it consumes fuel. In this case, $F=ma$ is incorrect. The correct formulation is:
$$
d(m(t)v(t)) = F dt
$$
This differential way of writing physical laws is powerful and provides the foundation for correctly interpreting stochastic equations. A Langevin equation written as $\dot{x} = f(x,t) + g(x,t)\xi(t)$ is mathematically problematic. The rigorous approach is to express it in its differential form using the Wiener process increment $dW_t$, which represents the integral of the white noise $\xi(t)$:
$$
dx = f(x,t)dt + g(x,t)dW_t
$$
This is a \textbf{Stochastic Differential Equation (SDE)}. Its solution is understood in an integral sense:
$$
x(t) = x_0 + \int_0^t f(x(\tau), \tau)d\tau + \int_0^t g(x(\tau), \tau)dW_\tau
$$
The second integral is a stochastic integral, an object whose properties are fundamentally different from the standard Riemann integral. The infinitesimal increment $dW_t$ is defined as $dW_t = W(t+dt) - W(t)$. As we have established, it is a Gaussian random variable with mean 0 and variance $dt$, so $dW_t \sim \mathcal{N}(0, dt)$. This can be expressed as:
$$
dW_t = G(t)\sqrt{dt}
$$
where $G(t)$ is a random variable drawn from the standard normal distribution, $\mathcal{N}(0,1)$.

The stochastic integral $\int_0^t g(x(\tau), \tau)dW_\tau$ represents the cumulative effect of the random forcing over time. Unlike deterministic integrals, this integral cannot be evaluated using traditional calculus rules due to the irregular nature of the Wiener process paths. The integral must be understood in the sense of Itô or Stratonovich, with Itô integration being the more commonly used convention in stochastic differential equations.

\begin{definitionblock}[Itô Equation]
Given an SLAE, we can always rewrite it as an \textbf{Itô equation}, by defining $dW = G(t)\sqrt{dt}$:
$$
dx = f(x)dt + g(x)dW
$$
\end{definitionblock}

\subsection{The Euler-Maruyama Method}

The Itô equation can be solved numerically using the Maruyama algorithm for stochastic differential equations. This is essentially the stochastic version of Euler's algorithm. Given a time interval $[0, T]$ and $h = T/N$, so that $t = jh$ for $j = 0, \ldots, N$. Suppose the Euler algorithm is:
$$
dx = x(t_j + h) - x(t_j) = x(t_{j+1}) - x(t_j)
$$
we can set $dt \approx h$ and write:
$$
x(t_{j+1}) = x(t_j) + f(x(t_j))h
$$

The Maruyama formula starts from this form by also considering the Gaussian effect, adding:
$$
x(t_{j+1}) = x(t_j) + f(x(t_j))h + G_j\sqrt{h}
$$
with $G_j \sim \mathcal{N}(0,1)$. Obviously, starting from this algorithm, more precise variants have been successively created.

\begin{definitionblock}[The Euler-Maruyama Method]
For the stochastic differential equation $dX_t = a(X_t, t)dt + b(X_t, t)dW_t$ with initial condition $X(0) = x_0$ and uniform time step $h$, the Euler-Maruyama approximation is given by:
$$
X_{j+1} = X_j + a(X_j, t_j)h + b(X_j, t_j)\sqrt{h}G_j
$$
where $t_j = jh$ and $\{G_j\}_{j=0}^{N-1}$ is a sequence of independent standard normal random variables.
\end{definitionblock}

This numerical scheme provides a practical foundation for simulating stochastic processes, though more sophisticated methods have been developed to improve accuracy and stability for specific applications.

\section{Basic Applications of SDEs}

\subsection{The Stochastic Malthusian Model and its Paradox}

The simplest model of population growth is the Malthusian model, which assumes an unlimited environment and a constant per capita growth rate, $r$. The dynamics are described by the ODE:
\vspace{0.4em}
$$
\dot{x} = rx
$$
where $x(t)$ represents the population size. The solution is simple exponential growth or decay, $x(t) = x(0)e^{rt}$. A more realistic model acknowledges that the growth rate is not constant but fluctuates randomly due to environmental variations. We can model this by making the growth rate a stochastic process, $r \to r + \omega\xi(t)$. This leads to the \bfit{stochastic Malthusian model}, an SDE with multiplicative noise:
$$
dx = (r + \omega\xi(t)) x
$$
where $\omega$ denotes the multiplicative noise amplitude. We can obtain the Ito formula:
$$
dx = rx\dd t + \omega x \dd W
$$
The solution of this stochastic equation can be obtained by applying Itô's formula. Setting $y = \ln x$, we find the drift and diffusion coefficients for the transformed process. Using Itô's rule:
\small
$$
dy = \left[ \frac{1}{x}rx - \frac{1}{2x^2}\omega^2 x^2 \right] \dd t + \dfrac 1x \omega x \dd W
\quad \xrightarrow{\text{simplifying}} \quad
dy = \left[r - \frac{\omega^2}{2}\right]dt + \omega dW
$$
\normalsize
This simplifies to a linear SDE which can be solved directly. Integrating from 0 to $t$:
$$
y(t) = y_0 + \left(r - \frac{\omega^2}{2}\right)t + \omega W(t)
$$
Supposing $W_0 = 0$, we can calculate the moments of $y(t)$:
$$
\langle y(t) \rangle = \langle y_0 \rangle + \left(r - \frac{\omega^2}{2}\right)t
$$
Therefore, if we have $\omega^2/2 > r$, then $y(t) \to -\infty$. We notice that, intuitively considering what $y(t)$ represents, if $\omega$ is large the population will tend to extinction regardless of $r$. In other words, a population highly subject to events, whether negative or positive, will tend to extinction.

We can then find the second moment of $y(t)$:
\small
$$
    \langle y(t)^2 \rangle = \left\langle \left[ y_0 + \left(r - \frac{\omega^2}{2}\right)t \right]^2 + 2\omega \left[ y_0 + \left(r - \frac{\omega^2}{2}\right)t \right] W(t) + \omega^2 W(t)^2 \right\rangle
$$
\normalsize
which, upon solving, becomes:
\vspace{-0.4em}
$$
    ... = \left[ y_0 + \left(r-\frac{\omega^2}{2}\right)t \right]^2 + \omega^2 t
$$
Assuming for convenience that $y_0$ is deterministic, then we have that the variance of $y(t)$ is:
$$
    \text{Var}[y(t)] = \langle y(t)^2 \rangle - \langle y(t) \rangle^2 = \omega^2 t
$$
Again, we can note that the variance tends to diverge over time. Returning now to $x(t)$, we have:
$$
    x(t) = e^{y(t)} = e^{y_0 + \left(r-\frac{\omega^2}{2}\right)t} e^{\omega W(t)}
=
    x(t) = x_0 e^{\left(r-\frac{\omega^2}{2}\right)t} e^{\omega W(t)}
$$
Then its mean value will be:
$$
    \langle x(t) \rangle = x_0 e^{\left(r-\frac{\omega^2}{2}\right)t} \langle e^{\omega W(t)} \rangle
$$

So, we must compute the mean of $\exp(\omega W(t))$. We know that $W(t)$ is distributed with the distribution:
$$
W(t) \sim N(0, t) = \frac{1}{\sqrt{2\pi t}} e^{-\frac{W^2}{2t}}
$$
so, to calculate the mean, we must compute:
$$
    \int_{-\infty}^{+\infty} \frac{1}{\sqrt{2\pi t}} e^{\omega W} e^{-\frac{W^2}{2t}} dW
$$
We can then combine the two exponentials and rewrite the resulting exponent as:
\large
$$
    e^{\frac{-W^2+2t\omega W -t^2\omega^2+t^2\omega^2}{2t}} = e^{-\frac{(W-t\omega)^2}{2t}} e^{\frac{\omega^2 t}{2}}
$$
\normalsize
As a consequence, the integral rewritten this way becomes:
$$
    ... = e^{\frac{\omega^2 t}{2}} \int_{-\infty}^{+\infty} \frac{1}{\sqrt{2\pi t}} e^{-\frac{(W-t\omega)^2}{2t}} dW
$$
This, however, is the integral of a translated Gaussian which is trivially equal to 1. Therefore:
\large
$$
    \langle e^{\omega W(t)} \rangle = e^{\frac{\omega^2 t}{2}}
$$
\normalsize
\vspace{-0.6em}
Thus,
\vspace{-0.3em}
\large
$$
    \langle x(t) \rangle = \langle x_0 \rangle e^{\left(rt - \frac{\omega^2 t}{2}\right) + \frac{\omega^2 t}{2}}
$$
\normalsize
In the Langevin hypothesis, it was the fact that the non-stochastic differential equation was nothing other than the differential equation of the mean, and here we find this result. Indeed, the two terms subtract, giving as a solution the solution of the non-stochastic case.

\subsubsection{The Paradox}

However, something strange emerges when we examine the long-term behavior. Returning to the definition of $y(t)$, we can rewrite it as:
$$
    y(t) = y_0 + \left(r - \frac{\omega^2}{2}\right)t + \omega\sqrt{t}G
$$
As $t \to \infty$, the deterministic term $\left(r - \frac{\omega^2}{2}\right)t$ dominates, so:
$$
    \lim_{t\to+\infty} y(t) = \begin{cases}
        -\infty & \text{if } r < \frac{\omega^2}{2} \\
        +\infty & \text{if } r > \frac{\omega^2}{2}
    \end{cases}
$$
Since $x(t) = e^{y(t)}$, when $y(t) \to -\infty$, we have $x(t) \to 0$. This creates an apparent paradox: we showed that $\langle x(t) \rangle = x_0 e^{rt}$, which always grows exponentially regardless of $\omega$, yet individual realizations $x(t)$ can tend to extinction when the noise is sufficiently large ($\omega^2/2 > r$).

The resolution lies in understanding the nature of the log-normal distribution. When $x(t) = e^{y(t)}$ where $y(t)$ is normally distributed, $x(t)$ follows a log-normal distribution, which is highly skewed. The mean and median can differ dramatically in such distributions.

\begin{exampleblock}[The Exponential Distribution]
Consider the simple exponential distribution with density $ae^{-aU}$. Its mean is $\langle U \rangle = 1/a$, but its median satisfies:
$$
    \int_0^{\text{MED}} ae^{-aU} dU = \frac{1}{2}
$$
which gives $\text{MED} = \log(2)/a < 1/a$. The median is smaller than the mean because the distribution has a long tail that pulls the mean upward.
\end{exampleblock}

Similarly, in our stochastic population model, $x(t)$ has a log-normal distribution. While the mean grows exponentially due to rare but extremely large population bursts, the typical behavior (represented by the median) can show decline when noise is large. The mean becomes dominated by infrequent but massive population explosions, making it a poor representative of typical outcomes.

\subsubsection{Calculation of the Median}

To quantify the typical behavior of the population, we need to calculate the median of $x(t)$. Since $y(t) \sim \mathcal{N}(\mu, \omega^2)$ where $\mu = y_0 + (r - \omega^2/2)t$ and the variance parameter is $\omega^2 t$, the random variable $x(t) = e^{y(t)}$ follows a log-normal distribution with probability density function:
$$
f_X(x) = \frac{1}{\sqrt{2\pi}\omega\sqrt{t} \cdot x} \exp\left(-\frac{(\log x - \mu)^2}{2\omega^2 t}\right), \quad x > 0
$$

The median $m$ is defined as the value satisfying $P(X \leq m) = 1/2$, which gives us the integral equation:
$$
\frac{1}{2} = \int_{0}^{m} \frac{1}{\sqrt{2\pi}\omega\sqrt{t} \cdot x} \exp\left(-\frac{(\log x - \mu)^2}{2\omega^2 t}\right) dx
$$

To solve this integral, we employ the substitution $w = \log x$, which transforms $dx = e^w dw = x \, dw$. The limits of integration become $w \in (-\infty, \log m]$, and our integral becomes:
$$
\frac{1}{2} = \int_{-\infty}^{\log m} \frac{1}{\sqrt{2\pi}\omega\sqrt{t}} \exp\left(-\frac{(w - \mu)^2}{2\omega^2 t}\right) dw
$$

This is precisely the cumulative distribution function of a normal random variable $\mathcal{N}(\mu, \omega^2 t)$ evaluated at $\log m$. Since the median of any normal distribution equals its mean, we have:
$$
\log m = \mu = y_0 + \left(r - \frac{\omega^2}{2}\right)t
$$

Therefore, the median of $x(t)$ is:
$$
\text{MED}[x(t)] = e^{\mu} = e^{y_0 + \left(r - \frac{\omega^2}{2}\right)t} = x_0 e^{\left(r - \frac{\omega^2}{2}\right)t}
$$

This result elegantly resolves the paradox. While the mean $\langle x(t) \rangle = x_0 e^{rt}$ always grows exponentially, the median, which better represents typical population trajectories, follows the drift-corrected dynamics. The long-term behavior of the median is:
$$
\lim_{t\to+\infty} \text{MED}[x(t)] = \begin{cases}
    0 & \text{if } r < \frac{\omega^2}{2} \quad \text{(extinction regime)} \\
    x_0 & \text{if } r = \frac{\omega^2}{2} \quad \text{(critical regime)} \\
    +\infty & \text{if } r > \frac{\omega^2}{2} \quad \text{(growth regime)}
\end{cases}
$$

The threshold $r = \omega^2/2$ represents a critical noise level: below this threshold, typical populations grow indefinitely, while above it, typical populations face extinction despite the exponentially growing mean. This dichotomy between mean and median behavior is a hallmark of log-normal processes and highlights the importance of choosing appropriate summary statistics for highly skewed distributions.

\newpage

\subsection{The Perturbed Logistic Equation}

We have discussed the fact that the Malthus model is not realistic because it assumes infinite resources. A much better model for population dynamics is the \textbf{Logistic model}, which incorporates a density-dependent growth rate. The deterministic logistic model can be written as follows:
$$
\dot{x} = r(x)x
$$
where $r(x)$ is a decreasing function of the population size $x$. The simplest choice for this function is linear:
$$
r(x) = r_0 - \alpha x
$$
Here, $r_0$ is the intrinsic growth rate at low densities, and $\alpha$ is a coefficient representing the strength of density-dependent regulation (e.g., competition for resources).

\subsubsection{Introducing Stochasticity}
In a realistic scenario, the intrinsic growth rate $r_0$ is not constant but fluctuates due to environmental variability. We can model its fast fluctuations as:
$$
r_0 \to r_0 + \omega\xi(t)
$$
where $\xi(t)$ is Gaussian white noise. This transforms the deterministic ODE into the stochastically perturbed logistic model:
$$
dx = (r_0 - \alpha x)x\,dt + \omega x\,dW_t
$$
To analyze this equation, we can again use the logarithmic transformation $y = \ln(x)$. Applying Itô's formula yields:
$$
dy = \left( r_0 - \frac{\omega^2}{2} - \alpha e^y \right) dt + \omega dW
$$
This transformed SDE can be formally integrated to give:
$$
y(t) = y(0) + \left( r_0 - \frac{\omega^2}{2} \right) t + \omega W(t) - \alpha \int_0^t e^{y(s)} ds
$$
We can now analyze the long-term behavior of the system. We know two key facts:
\begin{enumerate}
    \item If $\omega^2 > 2r_0$, then the non-integral part will tend to $-\infty$ as $t \to \infty$.
    \item The integral of the exponential is always positive since $x = e^y$ must be positive.
\end{enumerate}

\vspace{0.5em}

Slightly more precisely, the fact that $\int_0^t e^{y(s)}ds > 0$ gives us an upper bound on the process $y(t)$:
$$
y(t) \le y(0) + \left( r_0 - \frac{\omega^2}{2} \right) t + \omega W(t)
$$
This leads us to a \textbf{sufficient condition} for population extinction. If the right-hand side of the inequality goes to $-\infty$, then $y(t)$ must also go to $-\infty$. This happens when the drift of the bounding process is negative. Thus, the condition for extinction is:
$$
\frac{\omega^2}{2} > r_0 \quad \implies \quad \lim_{t\to\infty} x(t) = 0
$$
This powerful result shows that if the environmental noise is sufficiently strong, the population will go extinct regardless of the density-dependent term. The noise effectively suppresses the intrinsic growth.
